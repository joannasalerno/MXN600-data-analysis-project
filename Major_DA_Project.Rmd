---
title: "MXN600 Major Data Anaysis Project"
author: "Joanna Salerno, Pavan Asopa, Sevin Nejadi, Fernanda Martins Giuriati"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The credit risk models our lending start up company uses are of the utmost importance to the functioning and ultimate success of the company. As we were recently acquired by a regional Australian bank, the success of our company also impacts the success of the bank. Recently, some of the bank's senior financial analysts have raised concerns about the credit risk models we have been using. They reviewed our models' performance benchmarks and feel as though our models are not suitable for use in a setting in which they are subject to strict regulatory requirements.

Thus, we have been tasked by the bank's management to rebuild our credit risk model from the ground up. As per management, our main objective is to use information known at the time of a loan application to build a model that predicts loan default. We will follow a standard statistical analysis process, which will be guided by the following questions:

1. How does this new model perform compared to the one used previously? How can it be expected to perform on new loan applications?
2. What are the important variables in this model and how do they compare to variables that are traditionally important for predicting credit risk in the banking sector?

Furthermore, management has consulted with an expert statistician, who has suggested we also account for variation in trends that may exist either between different jurisdictions or over time. The following questions will guide this second part of our analysis:

3. Can accounting for this variation (e.g., state/zip-code and time) improve performance benchmarks?
4. Are there any surprising differences in variables that are important for predicting credit risk?
5. Does credit risk change over time or between states? This is not something the bank has previously
investigated and results may inform modified loan policies in the future.

This report will document our entire analysis process, beginning with data exploration and cleaning, to model building and interpretations of our results.

# Setup

We will first load in the required libraries for our data exploration and analysis process.

```{r load_libraries, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(MASS)
library(GGally)
library(lme4)
library(lmerTest)
library(DHARMa)
library(pROC)
library(dplyr)
```

Next, we will load in our datasets. We have a total of 4:

(1) A training dataset that we will use to build and train our model
(2) A test dataset that we will use to test the fit of our model(s)
(3) A validation dataset that we will use to assess the performance of our model(s)
(4) An extended dataset that includes the necessary variables for us to account for variation such as location and time

```{r load_data}
train_data <- read.csv("benchmark_training_loan_data.csv")
test_data <- read.csv("benchmark_testing_loan_data.csv")
val_data <- read.csv("benchmark_validation_loan_data.csv")
extended <- read.csv("extendend_version_loan_data.csv")
```

# Exploratory Analysis

We will begin by exploring the available data to understand how each variable is distributed and to identify any potential data quality issues. We will also investigate the relationships between the different variables to see whether any variables are highly correlated with one another.

Note: For this exploration portion of our analysis, we will be using the training dataset.

We will first explore the training dataset to understand its structure and the variables it is comprised of.

```{r head_data}
head(train_data)
```

At first glance of the first 6 rows of this dataset, we notice there is a value of n/a in the employment length column. There are also a few zero values in a few columns. This will prompt us to further explore the data for any true missing values.

```{r data_dim}
dim(train_data)
```

The training dataset contains a total of 23,052 observations of 19 variables.

```{r data_structure}
str(train_data)
```

Upon further investigation of the structure of the training data, we can see that 14 of the 19 variables are currently of numeric type, and the remaining 5 variables are characters.

We will now remove variable X, which is the number of each record, from all datasets, as it is not necessayr for this analysis.

```{r remove_X_from_datasets}
train_data <- train_data[, -1]
val_data <- val_data[, -1]
test_data <- test_data[, -1]
extended <- extended[, -1]
```

We will now further investigate each variable to determine whether there is any missing data or outliers.

```{r data_summary}
summary(train_data)
```

Included above is the numeric distributions of each of the included variables. Based on the above summary, it appears as though there may exist one or multiple outliers in a few variables: annual income, inquiries in the last 6 months, open accounts, revolving balances, and total accounts. However, we will need to further investigate the distribution of all variables to better visualize this to determine whether these actually appear to be outliers.

Before producing some exploratory plots, we will briefly explore the data to see whether there are missing values for us to handle.

```{r sum_na}
colSums(is.na(train_data))
```

Based on the above output, it appears as though this dataset does not contain any missing data in the form of NA values. Now, we will explore the n/a values present in the columns which include string data.

```{r string_na_sum}
sum(train_data == 'n/a')
```

```{r string_na_rows}
na_rows <- train_data %>% filter_all(any_vars(. %in% c('n/a')))
head(na_rows)
```

Based on the above output, there are a total of 591 n/a (string) in this dataset. These all appear to be from the employment length column. We will move forward and assume that this is not truly missing data, but rather, means that the applicant is not currently employed. We will further examine the ditribution of each variable by creating exploratory plots, and this will further clarify the meaning of some of the values contained within each column of the dataset.

## Exploratory Plots
### Data Preparation

Before we can create exploratory plots, there are a few variables we will need to convert to factors. This will help us in creating our visualizations as well as conducting our analyses, so we can consider the selected variables as factors with different levels rather than simply strings.

Training dataset:
```{r convert_vars_to_factors_train}
train_data$term <- as.factor(train_data$term)
train_data$emp_length <- as.factor(train_data$emp_length)
train_data$home_ownership <- as.factor(train_data$home_ownership)
train_data$verification_status <- as.factor(train_data$verification_status)
train_data$purpose <- as.factor(train_data$purpose)
train_data$repay_fail <- as.factor(train_data$repay_fail)
```

Test dataset:
```{r convert_vars_to_factors_test}
test_data$term <- as.factor(test_data$term)
test_data$emp_length <- as.factor(test_data$emp_length)
test_data$home_ownership <- as.factor(test_data$home_ownership)
test_data$verification_status <- as.factor(test_data$verification_status)
test_data$purpose <- as.factor(test_data$purpose)
test_data$repay_fail <- as.factor(test_data$repay_fail)
```

Validation dataset:
```{r convert_vars_to_factors_val}
val_data$term <- as.factor(val_data$term)
val_data$emp_length <- as.factor(val_data$emp_length)
val_data$home_ownership <- as.factor(val_data$home_ownership)
val_data$verification_status <- as.factor(val_data$verification_status)
val_data$purpose <- as.factor(val_data$purpose)
val_data$repay_fail <- as.factor(val_data$repay_fail)
```

Now, we'd like to briefly check whether there is an imbalance in the cases of repay_fail.

```{r check_imbalance_data}
plot(train_data$repay_fail)
```

Despite the significant class imbalance (repay_fail==0 v. repay_fail==1) in the dataset, logistic regression still maintains its probabilistic nature. However, it's important to note that imbalanced data can affect the model's predictive performance, potentially leading to a bias towards the majority class.

### Variable Distributions

Now, we will create some plots to visualize the distributions of some of the variables in this dataset.

```{r plots_1}
p1 <- ggplot(data = train_data, aes(int_rate, fill = repay_fail)) +
  geom_histogram(binwidth=5)

p2 <- ggplot(data = train_data, mapping = aes(x = verification_status, y = annual_inc)) +
  geom_boxplot() +
  theme_bw()

p3 <- ggplot(data = train_data, mapping = aes(x = repay_fail, y = loan_amnt)) +
  geom_boxplot() +
  theme_bw()

p4 <- ggplot(data = train_data, mapping = aes(x = repay_fail, y = annual_inc)) +
  geom_boxplot() +
  theme_bw()

p5 <- ggplot(data = train_data, mapping = aes(x = annual_inc, y = loan_amnt)) +
  geom_point() +
  theme_bw()

ggarrange(p1, p2)
ggarrange(p3, p4)
ggarrange(p5)
```

Explanations: 

Plot1 is a histogram that displays the distribution of interest rates in the dataset. The bars in the histogram are filled based on whether the loan was repaid successfully or not, where fill colours represent the two categories 0 for no failure and 1 for failure of loan repayment. Based on the plot, a trend can be seen that as the interest rate increases so does the chances of loan repayment failures.

Plot2 is a boxplot that shows the distribution of annual incomes based on different verification statuses. Each box represent a category of verification status. Based on the plot, we can see that we have similar sized boxes for all three categories which suggests that the median income for applicants in these categories is relatively consistent. However, we can see the presence of outlier in all three verification_status categories indicating that there are individuals with very high income within each group.

Plot3 is a boxplot that compares the loan amounts for both successfull and unsuccessfull loan repayments. Based on the plot, it can be seen that the median loan amount for both categories of loan repayment status are more or less consistent. The presence of outlier in both categories indicates that there are individuals with very high loan amount within each group. 

Plot4 is a boxplot that compares annual income between successful and unsuccessful loan repayments. Based on the plot it can be seen that most individuals that successfully paid off their loans are more or less consistent with the ones who failed with an exception of ouliers in both categories.

Plot5 is scatter plot that displays relationship annual income and loan amount. 

Now, we will visualize the distribution of each of the numeric variables in the dataset, using histograms:

```{r dist_plots_1}
numeric_vars <- c("loan_amnt", "annual_inc", "dti", "delinq_2yrs", "inq_last_6mths",
                  "open_acc", "pub_rec", "revol_util", "revol_bal", "total_acc",
                  "credit_age_yrs")
par(mfrow=c(3,4))
for (var in numeric_vars) {
  hist(train_data[[var]], main=var, xlab=var)
}
```

The above plots shows the distribution of the numeric variables within the dataset. These reveal that several variables, namely 'annual_inc,' 'delinq_2yrs,' 'inq_last_6mths,' 'pub_rec,' and 'revol_bal,' exhibit significant outliers, which can potentially impact the integrity of our analysis.

To address the presence of these outliers and to ensure the robustness of our subsequent statistical modeling, we have chosen to apply a scaling transformation to the numeric covariates in the dataset. The resulting scaled variables will enable us to conduct our analysis with a dataset that has been preprocessed to reduce the undue impact of outliers.

```{r dist_plots_2}
ggplot(train_data, aes(x = purpose)) +
  geom_bar() +
  labs(x = "Purpose", y = "Frequency") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The above bar plot represents the frequency of each unique value in the purpose variable. From the plot, it can be seen that the most common reasons to take out loans are for debt consolidation, credit cards, home improvement, and cars.

```{r dist_plots_3}
ggplot(train_data, aes(x = term, y = loan_amnt)) +
  geom_boxplot() +
  labs(x = "Term", y = "Loan Amount")
```

The above plot consists of two side-by-side boxplots, one for each loan term category. Each boxplot provides information about the distribution of loan amounts for its respective term category. Based on the plot, we can see that, on average, loans with 60-month terms have higher loan amounts than those with 36-month terms, which is an expected behaviour. Also, we can observe some outliers in the 36-month terms, which indicates that there are a few loan amounts which are significantly higher than the typical range of loan amounts for this term category.

Below, we create a correlation matrix of the numeric variables to help us understand the relationship between the different numeric variables.

```{r corr_matrix}
columns <- c("loan_amnt", "annual_inc", "dti", "delinq_2yrs", "inq_last_6mths", "open_acc", "pub_rec", "revol_util", "revol_bal", "total_acc", "credit_age_yrs","int_rate")
corr_matrix <- cor(train_data[columns], method = "pearson")
ggcorr(corr_matrix, hjust = 1, size = 3, color = "grey")
```

The correlation matrix (heatmap) reveals several noteworthy patterns:

Upon reviewing the correlation matrix, it becomes evident that certain features exhibit a high degree of positive correlation, such as "total_acc" and "open_acc." Additionally, "credit_age_yrs" and "total_acc," as well as "revol_util" and "int_rate," while not displaying correlations as strong as those between "total_acc" and "open_acc," still exhibit a notable level of correlation.

Following our examination of this matrix, each variable within pairs of highly correlated predictors will be analyzed while fitting models with the goal of identifying and refining the best model.

# New Credit Risk Model

Keeping our above exploratory analysis in mind, as well as reviewing the [Five Cs of Credit](https://www.investopedia.com/ask/answers/040115/what-most-important-c-five-cs-credit.asp) information, we have decided that the below variables are important predictors in assessing the risk of credit default:

annual_inc, emp_length, verification_status, dti, credit_age_yrs, home_ownership, total_acc, revol_bal, revol_util, int_rate, term, purpose, loan_amnt, inq_last_6mths, delinq_2yrs, pub_rec
                   
## Variable Standardization

Now, we'll move on to building our first model. We'll first need to standardize our numeric variables, because, as mentioned above, many of them have differing ranges and some include outliers. Scaling these numeric variables will allow for more accurate comparison so that all variables are on a similar scale.

Training dataset standardization:
```{r train_standardisation}
numeric_columns <- sapply(train_data, is.numeric)  # Identify numeric columns

# Scale the numeric columns while keeping column names
train_data[, numeric_columns] <- scale(train_data[, numeric_columns])

train_scaled_data <- train_data %>%
  mutate_if(is.numeric, scale)
```

Test dataset standardization:
```{r test_standardisation}
numeric_columns <- sapply(test_data, is.numeric)  # Identify numeric columns

# Scale the numeric columns while keeping column names
test_data[, numeric_columns] <- scale(test_data[, numeric_columns])

test_scaled_data <- test_data %>%
  mutate_if(is.numeric, scale)
```

Validation dataset standardization:
```{r val_standardisation}
numeric_columns <- sapply(val_data, is.numeric)  # Identify numeric columns

# Scale the numeric columns while keeping column names
val_data[, numeric_columns] <- scale(val_data[, numeric_columns])

val_scaled_data <- val_data %>%
  mutate_if(is.numeric, scale)
```

## Variable Selection

First, we have decided to perform stepwiseAIC to identify the most important predictors of loan default, from the list of variables we identified above: annual_inc, emp_length, verification_status, dti, credit_age_yrs, home_ownership, total_acc, revol_bal, revol_util, int_rate, term, purpose, loan_amnt, inq_last_6mths, delinq_2yrs, pub_rec.

```{r stepAIC}
# Full model for backwards selection:
full_model <- glm(repay_fail ~ loan_amnt + term + int_rate + emp_length + home_ownership + annual_inc + verification_status + purpose + dti + delinq_2yrs +
                    inq_last_6mths + open_acc + pub_rec + revol_bal + revol_util + total_acc + credit_age_yrs,
                  data = train_scaled_data, family = "binomial")

# Model with no variables present for forwards selection:
null_model <- glm(data = train_scaled_data,
    formula = repay_fail ~ 1,
    family = "binomial")

# Perform backward and forward selection:
backward_sel_model <- stepAIC(full_model, direction = "backward", trace = 0)

forward_sel_model <- stepAIC(
  null_model,
  scope = formula(full_model),
  direction = "forward",
  trace = 0) # prevents automatic output of stepAIC function
```

Now, we can view the model formulas and AIC values to ultimately choose the best one:

```{r backward_formula}
formula(backward_sel_model)
```

```{r forward_formula}
formula(forward_sel_model)
```

```{r backward_aic}
AIC(backward_sel_model)
```

```{r forward_aic}
AIC(forward_sel_model)
```

Based on the above output, both models produced the same formula (same list of covariates), as well as the same AIC values ($AIC = 18160.57$). Thus, we can select either to move forward with. We will choose the backward selection model, and will print the formula below again for review.

```{r chosen_formula}
formula(backward_sel_model)
```

According to stepwiseAIC, the best predictors of repay_fail are term, int_rate, emp_length, annual_inc, purpose, inq_last_6mths, pub_rec, revol_bal, and revol_util. We will move forward with these covariates to finetune a model that not only fits the data well but improves predictive performance compared to the credit risk model the bank has been using.

First, we'll create a model using the same exact formula suggested by stepAIC:

```{r fit_model1}
model1 <- glm(repay_fail ~ term + int_rate + emp_length + annual_inc + purpose + 
                inq_last_6mths + pub_rec + revol_bal + revol_util,
              data = train_scaled_data, family = "binomial")
```

Print the model's AIC:

```{r aic_model1}
AIC(model1)
```

As we already saw above and just reviewed, this model has an $AIC = 18160.57$. Next, we will add a few interactions between some of the covariates that make the most sense based on our credit risk research.

```{r fit_model2}
model2 <- glm(repay_fail ~ term + int_rate + emp_length + annual_inc + purpose + 
                inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                term * emp_length + term * annual_inc + term * purpose + term * pub_rec +
                int_rate * emp_length + int_rate * pub_rec + int_rate * annual_inc,
              data = train_scaled_data, family = "binomial")
```

Print the model's AIC:

```{r aic_model2}
AIC(model2)
```

The AIC of the new model is higher, with a value of 18173.81. This is to be expected, though, as this new model is penalized for having more covariates than the first model we fit. We will now perform a $\chi^2$-test to confirm whether the addition of these interactions are adding value to the model compared to the model without any interaction terms:

```{r anova_model1_model2}
anova(model1, model2, test = "Chisq")
```

As the $\chi^2$-test has a $p < 0.05$, this provides us with enough evidence to reject the null hypothesis that model 1 without interactions and model 2 with interactions explain the same amount of variation in the data. In other words, model 2 is significantly better at explaining the variation in the data compared to model 1. Thus, we will consider interactions between covariates. However, we will now decrease the number of interactions in our model, as model 2 included quite a few interactions. We will only consider the interaction between term and interest rate, as it seems to make sense that these two covariates together would have an impact on loan default risk.

```{r fit_model3}
model3 <- glm(repay_fail ~ term + int_rate + emp_length + annual_inc + purpose +
                inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate,
              data = train_scaled_data, family = "binomial")
```

Print the model's AIC:

```{r aic_model3}
AIC(model3)
```

The AIC of model 3 is lower than that of both model 1 and model 2. We will now conduct $\chi^2$-tests to confirm whether model 3 is significantly better at explaining the variation in the data than both model 1 and model 2.

```{r anova_model1_model3}
anova(model1, model3, test = "Chisq")
```

```{r anova_model2_model3}
anova(model2, model3, test = "Chisq")
```

As both $\chi^2$-tests have a $p < 0.05$, this indicates that model 3 is significantly better at explaining the variation in the data, as compared to both model 1 and model 2. We will move forward with model 3.

```{r summary_model3}
summary(model3)
```

## Logit Link Function

Next, we will fit a model using the logit link function, with our final list of covariates.

```{r fit_logit}
fit_logit <- glm(repay_fail ~ int_rate + emp_length + annual_inc + purpose + 
                   inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate,
                 data = train_scaled_data, family = binomial)

AIC(fit_logit)
```

This model has the lowest AIC value we have received thus far, and this, as well as the results of our $\chi^2$-tests, indicate that this is the best model at the moment. Thus, we will proceed with this model.

```{r summary_fit_logit}
summary(fit_logit)
```

### Logit Model Goodness of Fit

Before we try to interpret this model's summary, we will first check the goodness-of-fit to determine whether this model is actually a good fit for the data.

```{r fit_logit_resid}
# simulate residuals from the model:
res = simulateResiduals(fit_logit)

# plot observed quantile versus expected quantile to assess distribution fit, and
# predicted value versus standardised residuals for unmodelled pattern in the residuals
plot(res)
```

The above DHARMA residuals plots shows no sign of overdispersion. The distribution test (KS), dispersion test, and outlier test all are non-significant, which means there is evidence to suggest that the distribution of the simulated quantiles follows a uniform distribution. Additionally, in the second plot, the quantiles of the residuals (red lines) show a uniform pattern for predicted values.

### Logit Model: Predictive Performance

Next, we will analyse the predictive performance of our logit model. After all, this is one of the main reasons we've been tasked with conducting this analysis.

Training dataset ROC:
```{r train_roc}
# ROC curve on scaled train data 
prob=predict(fit_logit,type=c("response"))
g <- roc(train_scaled_data$repay_fail ~ prob)
AUC <- g$auc
AUC
Gini <- 2*(AUC - 1/2)
Gini
plot(g)
```

Validation dataset ROC:
```{r val_roc}
# ROC curve on scaled validation data
prob=predict(fit_logit,newdata=val_scaled_data,type=c("response"))
g <- roc(val_scaled_data$repay_fail ~ prob)
AUC <- g$auc
AUC
Gini <- 2*(AUC - 1/2)
Gini
plot(g)
```

The Gini score for the fitted logistic regression model is 0.410 on the training dataset and 0.395 on the validation dataset. Both of these scores are higher than those of the old model ($Gini=0.114$ for train, $Gini=0.110$ for validation). Additionally, the ROC curve for the new model is positioned closer to the top-left corner compared to the old model. These findings collectively indicate that the new model is better than the old one at predicting whether loan applicants will default.

## Probit Link Function

We will now test whether using a probit link function changes the AIC or predictive performance of our model.

```{r fit_probit}
fit_probit <- glm(repay_fail ~ int_rate + emp_length + annual_inc + purpose + inq_last_6mths +
                    pub_rec + revol_bal + revol_util + term * int_rate,
                  data = train_scaled_data, family = binomial("probit"))

AIC(fit_probit)
```

### Probit Model: Predictive Performance

Training dataset:
```{r probit_train_roc}
# Probit model: ROC curve on scaled train data 
prob=predict(fit_probit,type=c("response"))
g <- roc(train_scaled_data$repay_fail ~ prob)
AUC <- g$auc
AUC
Gini <- 2*(AUC - 1/2)
Gini
plot(g)
```

Validation dataset:
```{r probit_val_roc}
# Probit model: ROC curve on scaled validation data 
prob=predict(fit_probit,newdata = val_scaled_data,type=c("response"))
g <- roc(val_scaled_data$repay_fail ~ prob)
AUC <- g$auc
AUC
Gini <- 2*(AUC - 1/2)
Gini
plot(g)
```

While the model fit with a probit link function has lower AIC than the model with a logit link function, the probit model has a slightly lower Gini score on the validation set. We'll consider the logit model as better than the probit model.

## Cloglog Link Function

Finally, we will test whether using a cloglog link function changes the AIC or predictive performance of our model.

```{r fit_cloglog}
fit_cloglog <- glm(repay_fail ~ int_rate + emp_length + annual_inc + purpose + inq_last_6mths +
                     pub_rec + revol_bal + revol_util + term * int_rate,
                   data = train_scaled_data, family = binomial("cloglog"))

AIC(fit_cloglog)
```

As can be seen above, the model fit with the cloglog link function has a higher AIC than both the logit and probit models.

Based on the comparisons conducted between the three different link functions for our GLM model, we will choose to use the model with the logit link function as our final model. This model demonstrated the best combination of AIC value and predictive performance compared to the other models.

## Calculate Odds Ratio and CI

Next, we will calculate the odds ratios and confidence intervals for our final model. As this model was fit using the logit link function, we can exponentiate the estimates to get the odds ratio for each covariate.

```{r odds_ratio_GLM}
summary_logit <- summary(fit_logit)

parameter_estimates <- summary_logit$coef[, "Estimate"]
standard_errors <- summary_logit$coef[, "Std. Error"]
p_values <- summary_logit$coef[, "Pr(>|z|)"]

# Calculate the odds ratios by exponentiating the parameter estimate values
odds_ratios <- exp(parameter_estimates)

# Calculate the confidence intervals for the odds ratios
lower_ci <- exp(parameter_estimates - 1.96 * standard_errors)  # 1.96 corresponds to a 95% confidence interval
upper_ci <- exp(parameter_estimates + 1.96 * standard_errors)

model_results <- data.frame(
  Estimate = parameter_estimates,
  OddsRatio = odds_ratios,
  LowerCI = lower_ci,
  UpperCI = upper_ci,
  p_value = p_values
)

# Display results in a table
knitr::kable(
  model_results,
  col.names = c("Estimate", "Odds Ratio", "Lower Bound (2.5%)", "Upper Bound (97.5%)", "p-value")
)
```

Displaying only those variables whose p-value < 0.05:

```{r sig_results}
# Filter rows where p-value is less than 0.05
significant_results <- model_results[model_results$p_value < 0.05, ]

# Print the significant results
knitr::kable(
  significant_results,
  col.names = c("Estimate", "Odds Ratio", "Lower Bound (2.5%)", "Upper Bound (97.5%)", "p-value")
)
```

### Interpretations

Listed below are interpretations of the covariates of our final model:

- The intercept or baseline refers to individuals who have been employed for less than one year, are seeking a car loan, and have a 36-month loan term when all other numeric predictors are equal to zero, and is statistically significant (95% CI: [0.08,0.13], $p < 2e-16$).

- For a one-unit increase in the interest rate, the odds of "repay_fail" occurring increase by a factor of approximately 1.57 (95% CI: [1.48,1.67], $p < 2e-16$). This is a significant effect with a very low p-value.

- For individuals with 1 to 10 plus years of employment, none of these employment lengths have a significant effect on the odds of "repay_fail" occurring compared to the reference category (less than one year). Their odds ratios are close to 1, and all $p > 0.05$, indicating that these employment lengths do not significantly impact the likelihood of loan repayment failure.

For individuals with missing/unspecified employment lengths or unemployed individuals ("n/a"), the odds of "repay_fail" occurring increase by a factor of approximately 1.73 (95% CI: [1.37,2.19], $p = 4.11e-06$), compared to baseline (less than one year). This indicates that the absence of employment length information is associated with a higher likelihood of loan repayment failure.

- For a one-unit increase in annual income, the odds of "repay_fail" occurring decrease by a factor of approximately 0.71 (95% CI: [0.67,0.75], $p < 2e-16$).

- For loans with a stated purpose of "credit card", "debt consolidation", "educational", "home improvement", "house", "major purchase", "renewable energy", and "wedding", there is no significant effect on the odds of "repay_fail" occurring compared to the reference category (car). As all $p > 0.05$, these loan purposes do not significantly impact the likelihood of loan repayment failure.

For loans with a stated purpose of "medical", the odds of "repay_fail" occurring increase by a factor of approximately 1.83 (95% CI: [1.30-2.57], $p = 0.000502$), compared to the baseline (car).

For loans with a stated purpose of "moving", the odds of "repay_fail" occurring increase by a factor of approximately 1.65 (95% CI: [1.15,2.36], $p = 0.006978$), compared to baseline  (car).

For loans with a stated purpose of "other", the odds of "repay_fail" occurring increase by a factor of approximately 1.58 (95% CI: [1.24,2.00], $p = 0.000211$), compared to baseline  (car).

For loans with a stated purpose of "small business", the odds of "repay_fail" occurring increase by a factor of approximately 2.78 (95% CI: [2.15,3.59], $p = 5.80e-15$), compared to baseline  (car).

For loans with a stated purpose of "vacation", the odds of "repay_fail" occurring increase by a factor of approximately 1.56 (95% CI: [1.01,2.43], $p = 0.047421$), compared to baseline  (car). 

The specific loan purposes "medical," "moving," "other," and "small_business" are associated with a higher likelihood of loan repayment failure, and these effects are statistically significant. The effect of small business loan purpose is the most significant. "vacation" loans have a lesser degree of effect.
 
- For a one-unit increase in the number of inquiries in past 6 months, the odds of "repay_fail" occurring increase by a factor of approximately 1.24 (95% CI: [1.20,1.28], $p < 2e-16$). This is a significant effect with a very low p-value.

- For a one-unit increase in the number of derogatory public records, the odds of "repay_fail" occurring increase by a factor of approximately 1.06 (95% CI: [1.03,1.10], $p = 0.000332$). 

- For a one-unit increase in revolving balance, the odds of "repay_fail" occurring increase by a factor of approximately 1.10 (95% CI: [1.06,1.14], $p = 5.70e-06$).

- For a one-unit increase in revolving credit utilization, the odds of "repay_fail" occurring increase by a factor of approximately 1.12 (95% CI: [1.07,1.18], $p = 4.05e-07$).

- Having a 60-month loan term increases the odds of "repay_fail" occurring by a factor of approximately 1.67 (95% CI: [1.51,1.85], $p < 2e-16$), compared to the reference category (36 months loan term).

- The negative estimate for the interaction between interest rate and the 60-month term suggests that the effect of interest rate on "repay_fail" is less severe for loans with a 60-month term compared to the reference category of the 36-month term. In other words, while interest rate still has a significant impact on loan repayment on its own, its impact differs for loans with longer terms.

The interaction between interest rate and the 60-month loan term decreases the odds of "repay_fail" by a factor of approximately 0.90 (95% CI: [0.82,0.98], $p = 013086$), compared to baseline. The relationship between interest rate and loan repayment may differ depending on the term length, with the effect changing for longer-term loans.

## Odds Ratio Plot with CIs

```{r odds_ratio_plot_GLM}
plot_data <- data.frame(
  Variable = rownames(model_results),
  OddsRatio = model_results$OddsRatio,
  LowerCI = model_results$LowerCI,
  UpperCI = model_results$UpperCI
)

ggplot(plot_data, aes(x = OddsRatio, xmin = LowerCI, xmax = UpperCI, y = Variable)) +
  geom_point(size = 3, color="red") +
  geom_errorbarh(height = 0.2, color = "blue") +
  xlim(c(0, max(plot_data$UpperCI + 1))) +  
  theme_minimal() +
  labs(x = "Odds Ratio", y = "Variable") +
  ggtitle("Odds Ratios of Rapyment Failure for GLM")
```

Odds ratio of repayment failure for GLM model including confidence interval ranges compared to baseline: 36-month term, less than one year of employment, and loan purpose = car.

## Accuracy and Confusion Matrix

Finally, we will create a confusion matrix to demonstrate our final model's performance of classifying whether applicants will default on their payments or not.

```{r accuracy_confmatrix_GLM}
fit_logit <- ifelse(prob > 0.5, "1", "0")
fit_logit <- as.factor(fit_logit)

require(caret)
cm <- confusionMatrix(data=fit_logit,
                    reference=val_scaled_data$repay_fail,
                    positive="1")
cm
```

Included above is a confusion matrix, which depicts our model's true and false positive/negative rates. This can be used to better understand how well the model can predict new credit applications in terms of how accurately it classifies new applicants. The confusion matrix shows that out of 7,683 applicants, 6,504 of them will not default and have been accurately classified as so, and 21 of them will default and have been accurately classified as so. However, using our model, 1,138 applicants are falsely classified as defaulters when in fact, they would not have defaulted, and 20 applicants are falsely classified as not defaulting, when they are actually defaulters. 

## Part 1 Discussion

*** DISCUSS OVERALL FINDINGS

Can you confirm if we can conclude as below?? I added some as an example:

individuals with missing/unspecified employment lengths or unemployed individuals are more likely to repayment failure.

The relationship between interest rate and loan repayment may differ depending on the term length, with the effect changing for longer-term loans.

Loan with a 60-month loan term (longer term) are more likely to repayment failure.

The specific loan purposes "medical," "moving," "other," and "small_business" are associated with a higher likelihood of loan repayment failure, and these effects are statistically significant. The effect of small business loan purpose is the most significant while "vacation" loans have a lesser degree of effect.

Higher annual income ar less likely to repayment failure.
 
# Extended Credit Risk Model

Now, so far, we've been able to address management's concerns regarding the previous credit risk model and have presented a new model that performs much better. We are now going to address the second part of management's concerns, which includes using an extended version of the initial dataset. We will set out to answer whether accounting for variation in trends over jurisdiction or time changes or even improves performance benchmarks. Management has previously never considered whether credit risk changes between different states or over time, so we will investigate this.

We'll first take a look at the structure of the extended dataset.

```{r str_extended}
str(extended)
```

## Data Preparation

Next, we'll need to once again convert the relevant variables to factors. This time, this will include the new variables of zip_code, addr_state, and earliest_cr_line, in addition to the variables converted in the first part of this analysis:

```{r convert_vars_to_factors_ext}
extended$term <- as.factor(extended$term)
extended$emp_length <- as.factor(extended$emp_length)
extended$home_ownership <- as.factor(extended$home_ownership)
extended$verification_status <- as.factor(extended$verification_status)
extended$purpose <- as.factor(extended$purpose)
extended$repay_fail <- as.factor(extended$repay_fail)
extended$zip_code <- as.factor(extended$zip_code)
extended$addr_state <- as.factor(extended$addr_state)
extended$earliest_cr_line <- as.factor(extended$earliest_cr_line)
extended <- within(extended, location <- factor(as.factor(addr_state):zip_code)) # nest zip codes within states
```

```{r number of levels for each random effect}
nlevels(extended$zip_code)
nlevels(extended$addr_state)
nlevels(extended$location) # location includes zip nested within each state

nlevels(extended$earliest_cr_line)
```

## Variable Standardisation

Once again, we need to standardise the numeric variables in the dataset:

```{r standardisation_ext}
numeric_columns <- sapply(extended, is.numeric)  # Identify numeric columns

# Scale the numeric columns while keeping column names
extended[, numeric_columns] <- scale(extended[, numeric_columns])

extended_scaled <- extended %>%
  mutate_if(is.numeric, scale)
```

## Fit Models

We will begin to fit a GLMM to address this part of our analysis. We will use the same general model formula in terms of the inclusion of the same covariates. What will differ is the inclusion of random effects in this extended model. We will include random effects to account for variation in time and applicant location. We begin by fitting a model with just state as a random effect:

```{r extended_fit1}
fit_var_1 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|addr_state), data = extended_scaled, family = "binomial")
```

View first extended model summary with:

```{r summary_fit_var_1}
summary(fit_var_1)
```

As can be seen above, this model has an AIC value of 30131.5. Next, we'll add in another random effect of time, which is included as the variable "earliest_cr_line":

```{r fit_var_2}
fit_var_2 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|addr_state) + (1|earliest_cr_line), data = extended_scaled, family = "binomial")
```

Adding in time as a random effect caused a failed to converge warning. Thus, we will now increase the tolerance of this model to see if this helps:

```{r fit_var_3}
fit_var_3 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|addr_state) + (1|earliest_cr_line), data = extended_scaled, family = "binomial",
                   control = glmerControl(check.conv.grad = .makeCC("warning", tol = 3e-3, relTol = NULL)))
```

The model ran successfully, so we'll take a look at the summary:

```{r}
summary(fit_var_3)
```

The AIC value 30126.5, which is lower than that of the first extended model (fit_var_1). This indicates the new model with both added random effects of state and time is a better fit.

Now, we'll add in one more random effect, which is zip code. Once again, we will fit this model with an increased tolerance, compared to the default tolerance:

```{r fit_var_4}
fit_var_4 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|addr_state) + (1|earliest_cr_line) + (1|zip_code),
                   data = extended_scaled, family = "binomial",
                   control = glmerControl(check.conv.grad = .makeCC("warning", tol = 9e-3, relTol = NULL)))
```

Now we can view this model summary:

```{r summary_fit_var_4}
summary(fit_var_4)
```

Now, we'll try including just two random effects: earliest credit line (time), and then the new location factor we created earlier, which nests zip codes within each state:

```{r fit_var_5}
fit_var_5 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|location) + (1|earliest_cr_line),
                   data = extended_scaled, family = "binomial",
                   control = glmerControl(optimizer = "Nelder_Mead",
                                          check.conv.grad = .makeCC("warning", tol = 8e-3, relTol = NULL)))
```

View model summary:

```{r summary_fit_var_5}
summary(fit_var_5)
```

```{r extended_roc}
par(mfrow = c(1, 2))
# ROC curve on scaled extended data  for fit_var_4
prob=predict(fit_var_4,type=c("response"))
g <- roc(extended_scaled$repay_fail ~ prob)
AUC <- g$auc
Gini <- 2*(AUC - 1/2)
Gini
plot(g, main = "ROC Curve for fit_var_4")

# ROC curve on scaled extended data  for fit_var_5
prob=predict(fit_var_5,type=c("response"))
g <- roc(extended_scaled$repay_fail ~ prob)
AUC <- g$auc
Gini <- 2*(AUC - 1/2)
Gini
plot(g, main = "ROC Curve for fit_var_5")
```

As the tolerance level for the above model was a bit high, we are now going to try to tune other paramaters to see if this allows for a lower tolerance.

```{r}
fit_var_6 <- glmer(repay_fail ~ int_rate + emp_length + annual_inc + purpose +
                     inq_last_6mths + pub_rec + revol_bal + revol_util + term * int_rate +
                     (1|addr_state) + (1|earliest_cr_line) + (1|zip_code),
                   data = extended_scaled, family = binomial,
                   control = glmerControl(optimizer = "Nelder_Mead", tolPwrss = 1e-3))
```


*** EXPLAIN


## Analyse Performance Benchmarks

Analyse model with larger tolerance (all random effects separate):

```{r gof_fit_var_4}
# simulate residuals from the model:
res = simulateResiduals(fit_var_4)

# plot observed quantile versus expected quantile to assess distribution fit, and predicted value versus standardised residuals for unmodelled pattern in the residuals
plot(res)
```

Analyse model with random effects of (1) time and (2) zip code nested within state:

```{r gof_fit_var_5}
# simulate residuals from the model:
res = simulateResiduals(fit_var_5)

# plot observed quantile versus expected quantile to assess distribution fit, and predicted value versus standardised residuals for unmodelled pattern in the residuals
plot(res)
```

Does the model fit the data well?

```{r Goodness-of-fit}
plot(residuals(fit_var_5),
     ylab = "Residuals")
```

Look at the distribution of the random effects:

```{r res,include=TRUE}
res <- ranef(fit_var_5)

hist(res$earliest_cr_line[,1])

hist(res$location[,1])
```

## Calculate Odds Ratio and CIs

*** Now, we will ...

```{r odds_ratio_GLMM}
summary_fit5 <- summary(fit_var_5)

parameter_estimates2 <- summary_fit5$coef[, "Estimate"]
standard_errors2 <- summary_fit5$coef[, "Std. Error"]
p_values2 <- summary_fit5$coef[, "Pr(>|z|)"]

# Calculate the odds ratios by exponentiating the parameter estimate values
odds_ratios2 <- exp(parameter_estimates2)

# Calculate the confidence intervals for the odds ratios
lower_ci2 <- exp(parameter_estimates2 - 1.96 * standard_errors2)  # 1.96 corresponds to a 95% confidence interval
upper_ci2 <- exp(parameter_estimates2 + 1.96 * standard_errors2)

model_results2 <- data.frame(
  Estimate = parameter_estimates2,
  OddsRatio = odds_ratios2,
  LowerCI = lower_ci2,
  UpperCI = upper_ci2,
  p_value = p_values2
)

# Display results in a table
knitr::kable(
  model_results2,
  col.names = c("Estimate", "Odds Ratio", "Lower Bound (2.5%)", "Upper Bound (97.5%)", "p-value")
)
```

Displaying only those variables whose p-value is less than 0.05:

```{r}
# Filter rows where p-value is less than 0.05
significant_results2 <- model_results2[model_results2$p_value < 0.05, ]

# Print the significant results
knitr::kable(
  significant_results2,
  col.names = c("Estimate", "Odds Ratio", "Lower Bound (2.5%)", "Upper Bound (97.5%)", "p-value")
)
```

## Odds Ratio Plot

Odds ratio of repayment failure for GLMM model including confidence interval ranges compared to baseline: 36-month term, less than one year of employment, and loan purpose = car.

```{r odds_ratio_plot_GLM}
plot_data <- data.frame(
  Variable = rownames(model_results2),
  OddsRatio = model_results2$OddsRatio,
  LowerCI = model_results2$LowerCI,
  UpperCI = model_results2$UpperCI
)

ggplot(plot_data, aes(x = OddsRatio, xmin = LowerCI, xmax = UpperCI, y = Variable)) +
  geom_point(size = 3, color="red") +
  geom_errorbarh(height = 0.2, color = "blue") +
  xlim(c(0, max(plot_data$UpperCI + 1))) +  
  theme_minimal() +
  labs(x = "Odds Ratio", y = "Variable") +
  ggtitle("Odds Ratios of Rapyment Failure for GLMM")
```

### Interpretations

Accounting for variation in time and location does have an impact on our model. In particular, accounting for this variation results in an addition of four newly significant covariates, which are all loan purpose categories:

* purpose == debt_consolidation

For loans with a stated purpose of debt consolidation, the odds of "repay_fail" occurring increase by a factor of approximately 1.24 (95% CI: [1.04-1.48], $p = 0.016010$), compared to the baseline.

* purpose == educational

For loans with a stated purpose of education, the odds of "repay_fail" occurring increase by a factor of approximately 2.03 (95% CI: [1.50-2.76], $p = 0.0000068$), compared to the baseline.

* purpose == home_improvement

For loans with a stated purpose of home improvement, the odds of "repay_fail" occurring increase by a factor of approximately 1.23% (95% CI: [1.00-1.50], $p = 0.0479871$), compared to the baseline.

* purpose == renewable_energy

For loans with a stated purpose of renewable energy, the odds of "repay_fail" occurring increase by a factor of approximately 1.82% (95% CI: [1.00-3.28], $p = 0.0470893$), compared to the baseline.

Beyond these differences, this extended model had the same general set of significant covariates and interactions, in the same directions, though the effect sizes and significance values may vary.

## Part 2 Discussion

*** ...

# Conclusion

*** ...

## Caveats

* Imbalance of repay_fail class: Many more cases of non-failure to repay, which might influence the model to favour that outcome
* Extended model has a relatively high tolerance value, which could potentially be further reduced by tuning other model parameters
* We have only included a subset of the possible variables which may help to predict loan default
* We do not know the time frame of the data that is included, and it might be helpful to know this to ensure that we use recent data for model building and prediction tasks

## Future Directions

* You might want to explore other variables and interactions between variables that may help to predict loan default
* If provided with a validation dataset which included the extended variables of location and time, you could choose to use the extended model to predict loan default, and compare the extended model's prediction performance with that of the new model from part 1 of this analysis

# References

Listed below are the references we consulted to conduct this analysis.

[Control of Mixed Model Fitting](https://search.r-project.org/CRAN/refmans/lme4/html/lmerControl.html)

[Five Cs of Credit](https://www.investopedia.com/ask/answers/040115/what-most-important-c-five-cs-credit.asp)

[lme4 Convergence Warnings: Troubleshooting](https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html)

[lme4 Performance Tips](https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html#:~:text=choice%20of%20optimizer,may%20be%20worth%20a%20try.)

